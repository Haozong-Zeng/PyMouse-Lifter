{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_path   = Path('./assets/PyMouseLifter_demo/output/raw_video.mp4') \n",
    "depth_path = Path('./assets/PyMouseLifter_demo/output/depth_vis.mp4') \n",
    "label_txt  = Path('./assets/PyMouseLifter_demo/output/behavior_classification.txt') \n",
    "\n",
    "out_path   = Path('./assets/PyMouseLifter_demo/output/PyMouseLifter_demo.mp4')\n",
    "\n",
    "target_w = None   # e.g. 640\n",
    "target_h = None   # e.g. 480\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "æ‹¼æŽ¥ä¸­: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1800/1800 [00:14<00:00, 128.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å®Œæˆï¼Œè¾“å‡ºå·²ä¿å­˜åˆ° assets/PyMouseLifter_demo/output/PyMouseLifter_demo.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import re, cv2, colorsys, numpy as np\n",
    "from tqdm import tqdm\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ read labels â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "pattern = re.compile(r\"Frame\\s+(\\d+):\\s+\\['(.+)'\\]\")\n",
    "labels = {}\n",
    "with open(label_txt, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        m = pattern.search(line)\n",
    "        if m:\n",
    "            labels[int(m.group(1))] = m.group(2)\n",
    "\n",
    "# ðŸ”¹ 1) behavior to color mapping  --------------------------------------------\n",
    "behaviors = sorted(set(labels.values()))\n",
    "n_behav   = len(behaviors)\n",
    "behav2color = {}\n",
    "for i, beh in enumerate(behaviors):\n",
    "    # Take the HSV hue evenly, then convert it to BGR (cv2 defaults to BGR).\n",
    "    h = i / max(n_behav, 1)                 # hue âˆˆ [0,1)\n",
    "    r, g, b = colorsys.hsv_to_rgb(h, 1, 1)  # fullâ€‘sat, fullâ€‘val\n",
    "    behav2color[beh] = (int(b*255), int(g*255), int(r*255))  # BGR\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ‰“å¼€è§†é¢‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "cap_rgb   = cv2.VideoCapture(str(rgb_path))\n",
    "cap_depth = cv2.VideoCapture(str(depth_path))\n",
    "if not (cap_rgb.isOpened() and cap_depth.isOpened()):\n",
    "    raise IOError('âŒ cannot open input behavior')\n",
    "\n",
    "n_frames = int(cap_rgb.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "assert n_frames == int(cap_depth.get(cv2.CAP_PROP_FRAME_COUNT)), \\\n",
    "       'The frame rates of the two video streams are inconsistent!'\n",
    "\n",
    "fps  = cap_rgb.get(cv2.CAP_PROP_FPS)\n",
    "w_in = int(cap_rgb.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h_in = int(cap_rgb.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# target size\n",
    "target_w = target_w or w_in\n",
    "target_h = target_h or h_in\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "writer = cv2.VideoWriter(str(out_path), fourcc, fps,\n",
    "                         (target_w * 2, target_h))\n",
    "\n",
    "# å­—ä½“è®¾ç½®\n",
    "font, fscale, fthick = cv2.FONT_HERSHEY_SIMPLEX, 2, 4\n",
    "offset = (30, 60)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ loop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "for idx in tqdm(range(n_frames), desc='Splicing'):\n",
    "    ret1, frame_rgb   = cap_rgb.read()\n",
    "    ret2, frame_depth = cap_depth.read()\n",
    "    if not (ret1 and ret2):\n",
    "        print(f'âš ï¸ frame {idx} read failed, terminated early.'); break\n",
    "\n",
    "    # resize\n",
    "    if (frame_rgb.shape[1], frame_rgb.shape[0]) != (target_w, target_h):\n",
    "        frame_rgb = cv2.resize(frame_rgb, (target_w, target_h),\n",
    "                               interpolation=cv2.INTER_CUBIC)\n",
    "    if (frame_depth.shape[1], frame_depth.shape[0]) != (target_w, target_h):\n",
    "        frame_depth = cv2.resize(frame_depth, (target_w, target_h),\n",
    "                                 interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    # ðŸ”¹ 2) Overlay labels (written on the depth view) --------------------------------------\n",
    "    label_txt = labels.get(idx, '')\n",
    "    if label_txt != 'Stationary':\n",
    "        color     = behav2color.get(label_txt, (255, 255, 255))\n",
    "        text_sz, _ = cv2.getTextSize(label_txt, font, fscale, fthick)\n",
    "        tx = target_w - text_sz[0] - offset[0] \n",
    "        ty = offset[1]\n",
    "        cv2.putText(frame_depth, label_txt, (tx, ty),\n",
    "                    font, fscale, color, fthick, cv2.LINE_AA)\n",
    "    # --------------------------------------------------------------------\n",
    "\n",
    "    writer.write(np.concatenate((frame_rgb, frame_depth), axis=1))\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ release â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "cap_rgb.release(); cap_depth.release(); writer.release()\n",
    "print(f'âœ… Finished, output saved at {out_path}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyMouseLifter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
